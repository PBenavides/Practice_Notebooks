{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/37370015/what-is-the-difference-between-value-iteration-and-policy-iteration#:~:text=In%20Value%20Iteration%20%2D%20You%20randomly,%E2%80%94%2D%3E%20Policy%20improvement%E2%80%9D.\n",
    "\n",
    "### ¿Qué se quiere hacer?\n",
    "\n",
    "Aprender a escoger las acciones que maximicen los rewards.\n",
    "\n",
    "**¿Qué es policy?**\n",
    "\n",
    "Es una función que se aplica a algún estado para obtener alguna acción óptima. Se puede ver como el criterio que tiene el agente para poder decidir hacer una acción según sea el estado observado.\n",
    "\n",
    "**¿Qué es Value?**\n",
    "\n",
    "Es el valor que se usa para poder comparar una serie de acciones disponible en tiempo t, no solo considerando el Reward más cercano sino todos los rewards futuros en el proceso. Es útil pues ayuda a no tomar acciones a corto-plazo sino también considerar las acciones a largo-plazo. En este sentido, la ecuación de Bellman es muy útil para poder desarrollar estos conceptos.\n",
    "\n",
    "##### Value iteration:\n",
    "\n",
    "- Dados el ambiente, se calculan los valores que se incurrirían en todas las acciones disponibles. Así tendríamos una política acorde a todos los valores futuros según un estado dado. Es decir, el agente podría decidir en base al valor esperado qué decisión tomar.\n",
    "\n",
    "\n",
    "\n",
    "##### Policy iteration:\n",
    "\n",
    "- Se empieza con una política random, cual sea tomada y se irá mejorando esta tras las iteracieones. \n",
    "\n",
    "- Se calculan los valores de los estados de acuerdo a esa política dada, para luego actualizar estos valores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make('FrozenLake-v0')\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sacamos el policy según Value iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Policy iteration. Optimizamos el policy-"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
